[2021-02-28 04:26:16,471] {taskinstance.py:669} INFO - Dependencies all met for <TaskInstance: parse_goods.run_spider_goods 2021-02-27T00:00:00+00:00 [queued]>
[2021-02-28 04:26:16,490] {taskinstance.py:669} INFO - Dependencies all met for <TaskInstance: parse_goods.run_spider_goods 2021-02-27T00:00:00+00:00 [queued]>
[2021-02-28 04:26:16,490] {taskinstance.py:879} INFO - 
--------------------------------------------------------------------------------
[2021-02-28 04:26:16,490] {taskinstance.py:880} INFO - Starting attempt 1 of 2
[2021-02-28 04:26:16,490] {taskinstance.py:881} INFO - 
--------------------------------------------------------------------------------
[2021-02-28 04:26:16,499] {taskinstance.py:900} INFO - Executing <Task(BashOperator): run_spider_goods> on 2021-02-27T00:00:00+00:00
[2021-02-28 04:26:16,503] {standard_task_runner.py:53} INFO - Started process 96625 to run task
[2021-02-28 04:26:21,770] {logging_mixin.py:112} INFO - Running %s on host %s <TaskInstance: parse_goods.run_spider_goods 2021-02-27T00:00:00+00:00 [running]> Maxims-MacBook-Air.local
[2021-02-28 04:26:26,803] {bash_operator.py:82} INFO - Tmp dir root location: 
 /var/folders/yy/cdksfv594ms0d4n7_jss_mm40000gn/T
[2021-02-28 04:26:26,805] {bash_operator.py:105} INFO - Temporary script location: /var/folders/yy/cdksfv594ms0d4n7_jss_mm40000gn/T/airflowtmpmgsttq1c/run_spider_goodss_t26r0a
[2021-02-28 04:26:26,806] {bash_operator.py:115} INFO - Running command: #!/bin/bash

cd /Users/maxim/PycharmProjects/airflow/dags/parse_goods/scrapAmazon/scrapAmazon/spiders
scrapy crawl reviewsspider
[2021-02-28 04:26:26,823] {bash_operator.py:122} INFO - Output:
[2021-02-28 04:26:33,944] {bash_operator.py:126} INFO - 2021-02-28 04:26:33 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapAmazon)
[2021-02-28 04:26:34,081] {bash_operator.py:126} INFO - 2021-02-28 04:26:34 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.8 (v3.7.8:4b47a5b6ba, Jun 27 2020, 04:47:50) - [Clang 6.0 (clang-600.0.57)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.4.3, Platform Darwin-19.6.0-x86_64-i386-64bit
[2021-02-28 04:26:34,082] {bash_operator.py:126} INFO - 2021-02-28 04:26:34 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
[2021-02-28 04:26:34,090] {bash_operator.py:126} INFO - 2021-02-28 04:26:34 [scrapy.crawler] INFO: Overridden settings:
[2021-02-28 04:26:34,091] {bash_operator.py:126} INFO - {'AUTOTHROTTLE_ENABLED': True,
[2021-02-28 04:26:34,092] {bash_operator.py:126} INFO -  'BOT_NAME': 'scrapAmazon',
[2021-02-28 04:26:34,092] {bash_operator.py:126} INFO -  'FEED_EXPORT_ENCODING': 'utf-8',
[2021-02-28 04:26:34,093] {bash_operator.py:126} INFO -  'NEWSPIDER_MODULE': 'scrapAmazon.spiders',
[2021-02-28 04:26:34,093] {bash_operator.py:126} INFO -  'SPIDER_MODULES': ['scrapAmazon.spiders'],
[2021-02-28 04:26:34,094] {bash_operator.py:126} INFO -  'USER_AGENT': ('Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_2) '
[2021-02-28 04:26:34,094] {bash_operator.py:126} INFO -                 'AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.4 '
[2021-02-28 04:26:34,095] {bash_operator.py:126} INFO -                 'Safari/605.1.15',)}
[2021-02-28 04:26:34,119] {bash_operator.py:126} INFO - 2021-02-28 04:26:34 [scrapy.extensions.telnet] INFO: Telnet Password: 07e2911ae227cc9e
[2021-02-28 04:26:34,237] {bash_operator.py:126} INFO - 2021-02-28 04:26:34 [scrapy.middleware] INFO: Enabled extensions:
[2021-02-28 04:26:34,237] {bash_operator.py:126} INFO - ['scrapy.extensions.corestats.CoreStats',
[2021-02-28 04:26:34,238] {bash_operator.py:126} INFO -  'scrapy.extensions.telnet.TelnetConsole',
[2021-02-28 04:26:34,238] {bash_operator.py:126} INFO -  'scrapy.extensions.memusage.MemoryUsage',
[2021-02-28 04:26:34,239] {bash_operator.py:126} INFO -  'scrapy.extensions.logstats.LogStats',
[2021-02-28 04:26:34,239] {bash_operator.py:126} INFO -  'scrapy.extensions.throttle.AutoThrottle']
[2021-02-28 04:26:34,381] {bash_operator.py:126} INFO - 2021-02-28 04:26:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
[2021-02-28 04:26:34,382] {bash_operator.py:126} INFO - ['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
[2021-02-28 04:26:34,383] {bash_operator.py:126} INFO -  'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
[2021-02-28 04:26:34,383] {bash_operator.py:126} INFO -  'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
[2021-02-28 04:26:34,384] {bash_operator.py:126} INFO -  'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
[2021-02-28 04:26:34,385] {bash_operator.py:126} INFO -  'scrapy.downloadermiddlewares.retry.RetryMiddleware',
[2021-02-28 04:26:34,385] {bash_operator.py:126} INFO -  'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
[2021-02-28 04:26:34,385] {bash_operator.py:126} INFO -  'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
[2021-02-28 04:26:34,386] {bash_operator.py:126} INFO -  'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
[2021-02-28 04:26:34,386] {bash_operator.py:126} INFO -  'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
[2021-02-28 04:26:34,386] {bash_operator.py:126} INFO -  'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
[2021-02-28 04:26:34,387] {bash_operator.py:126} INFO -  'scrapy.downloadermiddlewares.stats.DownloaderStats']
[2021-02-28 04:26:34,388] {bash_operator.py:126} INFO - 2021-02-28 04:26:34 [scrapy.middleware] INFO: Enabled spider middlewares:
[2021-02-28 04:26:34,389] {bash_operator.py:126} INFO - ['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
[2021-02-28 04:26:34,390] {bash_operator.py:126} INFO -  'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
[2021-02-28 04:26:34,390] {bash_operator.py:126} INFO -  'scrapy.spidermiddlewares.referer.RefererMiddleware',
[2021-02-28 04:26:34,391] {bash_operator.py:126} INFO -  'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
[2021-02-28 04:26:34,392] {bash_operator.py:126} INFO -  'scrapy.spidermiddlewares.depth.DepthMiddleware']
[2021-02-28 04:26:34,393] {bash_operator.py:126} INFO - 2021-02-28 04:26:34 [scrapy.middleware] INFO: Enabled item pipelines:
[2021-02-28 04:26:34,393] {bash_operator.py:126} INFO - ['scrapAmazon.pipelines.ScrapamazonPipeline']
[2021-02-28 04:26:34,394] {bash_operator.py:126} INFO - 2021-02-28 04:26:34 [scrapy.core.engine] INFO: Spider opened
[2021-02-28 04:26:34,404] {bash_operator.py:126} INFO - 2021-02-28 04:26:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
[2021-02-28 04:26:34,406] {bash_operator.py:126} INFO - 2021-02-28 04:26:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
[2021-02-28 05:00:28,010] {bash_operator.py:126} INFO - 2021-02-28 05:00:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
[2021-02-28 05:00:28,703] {bash_operator.py:126} INFO - 2021-02-28 05:00:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://goods.ru/catalog/details/napolnitel-cat-step-selikagelevyy-152-l-100022760079/> (failed 1 times): DNS lookup failed: no results for hostname lookup: goods.ru.
[2021-02-28 05:00:28,705] {bash_operator.py:126} INFO - 2021-02-28 05:00:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://goods.ru/catalog/details/voda-mineralnaya-novoterskaya-gazirovannaya-15-l-plastik-100022961239/> (failed 1 times): DNS lookup failed: no results for hostname lookup: goods.ru.
[2021-02-28 05:00:28,706] {bash_operator.py:126} INFO - 2021-02-28 05:00:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://goods.ru/catalog/details/smart-chasy-apple-watch-se-44mm-space-gray-aluminium-case-with-black-sport-band-mydt2ru-a-100027259585/> (failed 1 times): DNS lookup failed: no results for hostname lookup: goods.ru.
[2021-02-28 05:00:28,846] {logging_mixin.py:112} INFO - [2021-02-28 05:00:28,718] {local_task_job.py:114} ERROR - Heartbeat time limited exceeded!
[2021-02-28 05:00:29,012] {helpers.py:325} INFO - Sending Signals.SIGTERM to GPID 96625
[2021-02-28 05:00:29,068] {taskinstance.py:954} ERROR - Received SIGTERM. Terminating subprocesses.
[2021-02-28 05:00:29,069] {bash_operator.py:140} INFO - Sending SIGTERM signal to bash process group
[2021-02-28 05:00:29,813] {taskinstance.py:1145} ERROR - Task received SIGTERM signal
Traceback (most recent call last):
  File "/Users/maxim/PycharmProjects/airflow/venv/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 983, in _run_raw_task
    result = task_copy.execute(context=context)
  File "/Users/maxim/PycharmProjects/airflow/venv/lib/python3.7/site-packages/airflow/operators/bash_operator.py", line 124, in execute
    for line in iter(self.sub_process.stdout.readline, b''):
  File "/Users/maxim/PycharmProjects/airflow/venv/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 956, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2021-02-28 05:00:29,966] {taskinstance.py:1168} INFO - Marking task as UP_FOR_RETRY
[2021-02-28 05:00:30,394] {helpers.py:291} INFO - Process psutil.Process(pid=96625, status='terminated') (96625) terminated with exit code 1
[2021-02-28 05:00:30,413] {helpers.py:291} INFO - Process psutil.Process(pid=96627, status='terminated') (96627) terminated with exit code None
[2021-02-28 05:00:40,609] {helpers.py:291} INFO - Process psutil.Process(pid=96628, status='terminated') (96628) terminated with exit code None
